# Matrix-Multiplication-Kronecker-Product-Form

Primary Algorithm : Efficiently multiply two matrices, as long as one can be expressed as a Kronecker product of two smaller matrices. The primary algorithm has significantly lower memory requirements and computational complexity relative to direct computation of the same quantities (O(n2.5) vs. O(n3))

Problem Formulation:

Addressing  a  variety  of  questions  within  Earth science disciplines entails the inference of the spatio temporal distribution of parameters of interest based on observations of related quantities. Such estimation problems often                                                                                                   represent inverse problems that are formulated as linear optimization  problems.  Computational  limitations  arise  when the number of observations and/or the size of the discretized state  space  becomes  large,  especially  if  the  inverse  problem  is  formulated  in  a  probabilistic  framework  and  therefore aims to assess the uncertainty associated with the estimates. This work proposes two approaches to lower the computational  costs  and  memory  requirements  for  large  linear spacetime inverse problems, taking the Bayesian approach for estimating carbon dioxide (CO2) emissions and uptake(a.k.a. fluxes) as a prototypical example. The first algorithm can be used to efficiently multiply two matrices, as long as one can be expressed as a Kronecker product of two smaller matrices, a condition that is typical when multiplying a sensitivity matrix by a covariance matrix in the solution of inverse problems. The second algorithm can be used to compute aposteriori uncertainties directly at aggregated spatio temporal scales, which are the scales of most interest in many inverseproblems. Both algorithms have significantly lower memory requirements and computational complexity relative to direct computation of the same quantities (O(n2.5) vs. O(n3)). For an examined benchmark problem, the two algorithms yielded massive savings in floating point operations relative to directcomputation of the same quantities. Sample computer codes are provided for assessing the computational and memory efficiency of the proposed algorithms for matrices of different dimensions.

Reference Paper:

Improving computational efficiency in large linear inverseproblems: an example from carbon dioxide flux estimation

Yadav, V. and Michalak, A. M.: Improving computational efficiency in large linear inverse problems: an example from carbon dioxide flux estimation, Geosci. Model Dev., 6, 583–590, https://doi.org/10.5194/gmd-6-583-2013, 2013. 

Downloadable from: https://www.geosci-model-dev.net/6/583/2013/gmd-6-583-2013.html

Code Description:

Two  MATLAB  code  files  demonstrating  the  applicationof   the   methods   proposed   in   this   manuscript   are   in-cluded as supplementary material. The MATLAB script file“HQHQHt.m”  allows  users  to  experiment  with  differentsizes of random covariance matrices in a Kronecker productform and computesHQandHQHTusing the direct methodas  well  as  the  method  presented  in  Sect.  2.1.  The  secondMATLAB script file “UncertaintyComputations.m” allowsusers to experiment with random matrices for computing aposteriori covariances aggregated either over all time periodsor for specified time periods. A detailed description of thecodes is also given at the beginning of the script files. Notethat these codes are provided to illustrate the two algorithmsproposed in this research, but these codes should not be usedto assess the computational performance of these algorithms.This is because MATLAB uses (1) highly optimized multi-threaded external libraries (Basic Algebra Subroutines) forperforming matrix multiplication, and (2) automatic memorymanagement (e.g., allocation and reallocation of memory).To  supplement  the  MATLAB  routines,  we  also  includecompletely serial Fortran (filename: HQ.f90) and C++(file-name: HQ.cpp) code for performing the matrix multiplica-tion ofHandQmatrix. Although the performance of thesecodes may vary depending on computer architecture, the per-formance will approximately reflect the computational sav-ings described in the manuscript. For example, for the For-tran code compiled using the GFortran compiler on a IntelXeon  X5660  2.80 GHz  machine  with  96 GB  RAM,  a  ma-trix  multiplication  (1)  withn=8503,r=t=10,  andp=q=100  took  approximately  12 s  using  the  direct  methodand approximately 2.2 s using the indirect method; (2) withn=8503,r=t=100,  andp=q=10,  the  direct  methodtook approximately 9.4 s whereas the indirect method tookapproximately  1.0 s;  and  (3)  withn=15000,r=t=150andp=q=150, the direct method took approximately 3 hwhereas the indirect method took approximately 3.4 min.
